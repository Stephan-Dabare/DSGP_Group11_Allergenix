{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "To apply pipeline techniques to the cosmetic dataset, the suggested technique was a hybrid technique which is a mix of both batch processing and real time."
      ],
      "metadata": {
        "id": "emwc6_9fXdvj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF62gp2CXZcD",
        "outputId": "fdfb85f3-acb8-45cd-e546-576324d34669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUqg5AZBYa3z",
        "outputId": "ef61cb4b-9245-4cc7-ecb6-30d1379325a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset from Google Drive\n",
        "file_path = '/content/drive/My Drive/product_info.csv'\n",
        "data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "kr0ifF6BYhN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l65nq1cuZ7IQ",
        "outputId": "e1ac7e5b-ebce-48e8-c6d4-0019375be0a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['product_id', 'product_name', 'brand_id', 'brand_name', 'loves_count',\n",
              "       'rating', 'reviews', 'size', 'variation_type', 'variation_value',\n",
              "       'variation_desc', 'ingredients', 'price_usd', 'value_price_usd',\n",
              "       'sale_price_usd', 'limited_edition', 'new', 'online_only',\n",
              "       'out_of_stock', 'sephora_exclusive', 'highlights', 'primary_category',\n",
              "       'secondary_category', 'tertiary_category', 'child_count',\n",
              "       'child_max_price', 'child_min_price'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['tertiary_category'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "GbzOcviybSM8",
        "outputId": "37a5d0e6-7d6d-415f-a2e9-94574717f3d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tertiary_category\n",
              "Perfume                      568\n",
              "Moisturizers                 386\n",
              "Face Serums                  379\n",
              "Rollerballs & Travel Size    287\n",
              "Hair Styling Products        255\n",
              "                            ... \n",
              "Under-Eye Concealer            3\n",
              "Sunscreen                      2\n",
              "Hair Thinning & Hair Loss      2\n",
              "Damaged Hair                   1\n",
              "Manicure & Pedicure Tools      1\n",
              "Name: count, Length: 118, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tertiary_category</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Perfume</th>\n",
              "      <td>568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Moisturizers</th>\n",
              "      <td>386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Face Serums</th>\n",
              "      <td>379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Rollerballs &amp; Travel Size</th>\n",
              "      <td>287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hair Styling Products</th>\n",
              "      <td>255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Under-Eye Concealer</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sunscreen</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hair Thinning &amp; Hair Loss</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Damaged Hair</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Manicure &amp; Pedicure Tools</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>118 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['primary_category'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "djVsHtjLYrcp",
        "outputId": "d83da9ac-8424-439e-c406-a2bcd25c2f9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "primary_category\n",
              "Skincare           2420\n",
              "Makeup             2369\n",
              "Hair               1464\n",
              "Fragrance          1432\n",
              "Bath & Body         405\n",
              "Mini Size           288\n",
              "Men                  60\n",
              "Tools & Brushes      52\n",
              "Gifts                 4\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>primary_category</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Skincare</th>\n",
              "      <td>2420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Makeup</th>\n",
              "      <td>2369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hair</th>\n",
              "      <td>1464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fragrance</th>\n",
              "      <td>1432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bath &amp; Body</th>\n",
              "      <td>405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mini Size</th>\n",
              "      <td>288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Men</th>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tools &amp; Brushes</th>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gifts</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter relevant columns and categories\n",
        "filtered_data = data[data['primary_category'].isin(['Skincare', 'Makeup', 'Hair', 'Fragrance'])]\n",
        "filtered_data = filtered_data[['ingredients', 'primary_category']]\n",
        "\n",
        "# Drop rows with missing ingredients\n",
        "filtered_data = filtered_data.dropna(subset=['ingredients'])\n"
      ],
      "metadata": {
        "id": "AZGDd4v7Zvq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Initialize tools\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_ingredients(text):\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    # Tokenize and remove stopwords\n",
        "    tokens = text.split()\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    # Lemmatize\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing\n",
        "filtered_data['ingredients_cleaned'] = filtered_data['ingredients'].apply(preprocess_ingredients)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrHJyZ8rc9In",
        "outputId": "50b7b180-2dae-454a-8ae2-1215b86bee95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "\n",
        "# Convert the filtered dataset to a Dask DataFrame\n",
        "dask_data = dd.from_pandas(filtered_data, npartitions=4)\n",
        "\n",
        "# Example pipeline: Preprocess and split into features and labels\n",
        "dask_data['ingredients_cleaned'] = dask_data['ingredients'].map(preprocess_ingredients, meta=('ingredients_cleaned', 'str'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smNxK1zgdHCo",
        "outputId": "1a5422c4-80f8-4641-f296-3a7614b751c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf = TfidfVectorizer(max_features=5000)  # Use top 5000 features\n",
        "\n",
        "# Fit and transform the text data\n",
        "X = tfidf.fit_transform(filtered_data['ingredients_cleaned'])\n",
        "y = filtered_data['primary_category']\n"
      ],
      "metadata": {
        "id": "qG2uBj1NdNad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest Classifier\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZGgErcvdcLl",
        "outputId": "e3623f72-4349-4899-94e9-948511d4e906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Fragrance       0.97      0.97      0.97       262\n",
            "        Hair       0.96      0.86      0.91       246\n",
            "      Makeup       0.94      0.91      0.92       411\n",
            "    Skincare       0.88      0.95      0.91       451\n",
            "\n",
            "    accuracy                           0.93      1370\n",
            "   macro avg       0.94      0.92      0.93      1370\n",
            "weighted avg       0.93      0.93      0.93      1370\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Predict using new ingredient data\n",
        "new_data = [\"WATER/EAU, SODIUM LAURYLSULFATE, SODIUM LAURETH SULFATE, COCAMIDOPROPYL BE- TAINE, GLYCOL DISTEARATE, DIMETHICONE, SODIUM CITRATE, COCAMIDE MEA, SODIUM XYLENESULFONATE, FRAGRANCE/ PARFUM, CITRIC ACID, SODIUM BENZOATE, POLYQUATERNI- UM-76, SODIUM CHLORIDE, TETRASODIUM EDTA, PANTHE- NOL, PANTHENYL ETHYL ETHER, METHYLCHLOROISOTHIAZOLIN- ONE, METHYLISOTHIAZOLINONE\"]\n",
        "new_data_preprocessed = [preprocess_ingredients(item) for item in new_data]\n",
        "new_data_tfidf = tfidf.transform(new_data_preprocessed)\n",
        "predictions = model.predict(new_data_tfidf)\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QK5pE8Pdm22",
        "outputId": "b3731185-fb80-485d-9e5b-f5764f17746b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hair']\n"
          ]
        }
      ]
    }
  ]
}