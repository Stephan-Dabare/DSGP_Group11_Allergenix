# -*- coding: utf-8 -*-
"""BERT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vlmbF4OepjyKybZKK_-TIEKOMlWltHR8
"""

import pandas as pd
import torch
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments
from torch.utils.data import Dataset

# Load datasets
df_all_rows = pd.read_csv('/content/all_rows (2).csv')
df_food_data = pd.read_csv('/content/FoodData.csv')

# Clean text (as described earlier)
def clean_text(text):
    if pd.isnull(text):
        return ''
    return text.lower().strip()

df_all_rows['allergens_clean'] = df_all_rows['allergens'].apply(clean_text)
df_food_data['Food_clean'] = df_food_data['Food'].apply(clean_text)

# Merge datasets
merged_data = pd.merge(df_all_rows, df_food_data, left_on='allergens_clean', right_on='Food_clean', how='left')

# Combine text features for model input
merged_data['text'] = (
    merged_data['ingredients_text'].fillna('') + ' ' +
    merged_data['additives_en'].fillna('')
)

# Drop rows with missing Allergy labels after merging
merged_data = merged_data.dropna(subset=['Allergy'])

# Encode the target labels
label_encoder = LabelEncoder()
merged_data['label'] = label_encoder.fit_transform(merged_data['Allergy'])

# Split into train and test sets
train_texts, test_texts, train_labels, test_labels = train_test_split(
    merged_data['text'], merged_data['label'], test_size=0.2, random_state=42
)

from torch.utils.data import Dataset
import torch

class AllergyDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length):
        self.texts = texts  # Expect a list of texts
        self.labels = labels  # Expect a list of labels
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        # Access list elements using Python indexing
        text = self.texts[idx]
        label = self.labels[idx]

        # Tokenize the text
        encoding = self.tokenizer(
            text,
            max_length=self.max_length,
            padding="max_length",
            truncation=True,
            return_tensors="pt"
        )

        # Return the data as a dictionary
        return {
            "input_ids": encoding["input_ids"].squeeze(0),
            "attention_mask": encoding["attention_mask"].squeeze(0),
            "labels": torch.tensor(label, dtype=torch.long)
        }

train_texts = train_texts.tolist()  # Ensure it is a Python list
test_texts = test_texts.tolist()    # Ensure it is a Python list
train_labels = train_labels.tolist()  # Ensure it is a Python list
test_labels = test_labels.tolist()    # Ensure it is a Python list

import os
from transformers import BertForSequenceClassification, BertTokenizer, Trainer, TrainingArguments
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

# Disable W&B logging if not required
os.environ["WANDB_DISABLED"] = "true"

# Load the tokenizer and model
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

num_labels = len(label_encoder.classes_)  # Ensure label_encoder is correctly loaded
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)

# Prepare datasets
train_dataset = AllergyDataset(
    texts=train_texts,
    labels=train_labels,
    tokenizer=tokenizer,
    max_length=128
)

eval_dataset = AllergyDataset(
    texts=test_texts,
    labels=test_labels,
    tokenizer=tokenizer,
    max_length=128
)

# Define training arguments
training_args = TrainingArguments(
    output_dir="./results",          # Directory to save model checkpoints
    num_train_epochs=3,              # Number of training epochs
    per_device_train_batch_size=16,  # Batch size per device during training
    per_device_eval_batch_size=64,   # Batch size for evaluation
    warmup_steps=500,                # Number of warmup steps for learning rate scheduler
    weight_decay=0.01,               # Strength of weight decay
    logging_dir='./logs',            # Directory for storing logs
    logging_steps=10,
)

# Define metric computation
def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')
    acc = accuracy_score(labels, preds)
    return {
        'accuracy': acc,
        'f1': f1,
        'precision': precision,
        'recall': recall
    }

# Fine-tune the model using Hugging Face's Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics
)

# Train the model
trainer.train()

# Fine-tune the model
# trainer.train()

# Evaluate the model
results = trainer.evaluate()

# Print evaluation metrics
print("Evaluation Results:", results)

# Sample input
sample_text = "Sugar, wheat flour, milk powder, cocoa butter, soy lecithin"

# Tokenize the input text
sample_tokenized = tokenizer(
    sample_text,
    max_length=128,
    truncation=True,
    padding="max_length",
    return_tensors="pt"
)

from sklearn.preprocessing import MultiLabelBinarizer

# Initialize and fit the MultiLabelBinarizer during training
mlb = MultiLabelBinarizer()
y = mlb.fit_transform(merged_data['Allergy'].str.split(',').tolist())

import pickle

# Save the fitted mlb
with open('mlb.pkl', 'wb') as f:
    pickle.dump(mlb, f)

import numpy as np

# Assuming 'model' and 'sample_tokenized' are defined from previous cells
with torch.no_grad():
    outputs = model(**sample_tokenized)  # Get model outputs
    predicted_class = torch.argmax(outputs.logits, dim=1).item()  # Get the predicted class index

# Convert predicted_class into a properly shaped NumPy array
predicted_array = np.zeros((1, len(mlb.classes_)))  # Create an array with the same number of classes
predicted_array[0, predicted_class] = 1  # Set the predicted class to 1 (one-hot encoded)

# Decode the predicted class to allergy type(s)
predicted_allergy = mlb.inverse_transform(predicted_array)
print(f"Predicted Allergy Type: {predicted_allergy}")

def predict_allergy(text, model, tokenizer, mlb, device, threshold=0.5):
    """
    Predict allergens for a given text.
    """
    encoding = tokenizer.encode_plus(
        text,
        add_special_tokens=True,
        max_length=512,
        return_token_type_ids=False,
        padding='max_length',
        truncation=True,
        return_attention_mask=True,
        return_tensors='pt',
    )

    input_ids = encoding['input_ids'].to(device)
    attention_mask = encoding['attention_mask'].to(device)

    with torch.no_grad():
        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        logits = outputs.logits
        probs = torch.sigmoid(logits).cpu().numpy()[0]

    # Apply threshold to get predicted allergies
    predicted_allergies = [mlb.classes_[i] for i, prob in enumerate(probs) if prob >= threshold]
    return predicted_allergies

from sklearn.metrics import accuracy_score, hamming_loss, precision_recall_fscore_support
import numpy as np

def evaluate_model_accuracy(model, tokenizer, test_texts, test_labels, mlb):
    """
    Evaluate the model on test data and calculate metrics.
    """
    # Tokenize test texts
    inputs = tokenizer(
        test_texts,  # Ensure this is a list of strings
        padding=True,
        truncation=True,
        max_length=128,
        return_tensors="pt"
    )

    # Move inputs to the model's device
    inputs = {key: val.to(model.device) for key, val in inputs.items()}

    # Predict logits
    model.eval()
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probabilities = torch.sigmoid(logits).cpu().numpy()  # Convert logits to probabilities

    # Apply threshold to convert probabilities into binary predictions
    threshold = 0.5
    y_pred = (probabilities >= threshold).astype(int)

    # Ensure `test_labels` is in multilabel-indicator format
    if isinstance(test_labels[0], int):  # Convert to multilabel-indicator if needed
        y_test = mlb.transform([[label] for label in test_labels])
    else:
        y_test = np.array(test_labels)

    # Calculate Exact Match Ratio
    exact_match_ratio = accuracy_score(y_test, y_pred)

    # Calculate Precision, Recall, and F1-Score
    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')

    # Calculate Hamming Loss (lower is better)
    hamming = hamming_loss(y_test, y_pred)

    # Output metrics
    metrics = {
        "Exact Match Ratio": exact_match_ratio,
        "Precision": precision,
        "Recall": recall,
        "F1-Score": f1,
        "Hamming Loss": hamming
    }
    return metrics

# Example usage
# Ensure test_labels is a list of lists or a multiclass integer list
metrics = evaluate_model_accuracy(model, tokenizer, test_texts, test_labels, mlb)
print("Model Evaluation Metrics:")
for metric, value in metrics.items():
    print(f"{metric}: {value:.4f}")

import torch

# Set device to GPU if available, otherwise use CPU
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
print(f"Using device: {device}")

# Ensure test_labels is in the correct format
print(f"First 5 entries of test_labels: {test_labels[:5]}")

# Convert test_labels to a list of lists if necessary
if isinstance(test_labels[0], int):
    # Single-label integer format, map to class labels
    test_labels_list = [[mlb.classes_[label]] for label in test_labels]
elif isinstance(test_labels[0], str):
    # Single-label string format, wrap in a list
    test_labels_list = [[label] for label in test_labels]
else:
    # Assume test_labels is already in the correct list-of-lists format
    test_labels_list = test_labels

# Transform to binary matrix
test_labels_binary = mlb.transform(test_labels_list)

# Debugging output
print(f"Shape of test_labels_binary: {test_labels_binary.shape}")

import numpy as np

# Convert integer labels to binary matrix
num_classes = len(mlb.classes_)
test_labels_binary = np.zeros((len(test_labels), num_classes), dtype=int)

for i, label in enumerate(test_labels):
    test_labels_binary[i, label] = 1

print(f"Shape of test_labels_binary: {test_labels_binary.shape}")
print("First 5 rows of test_labels_binary:")
print(test_labels_binary[:5])

# Generate predictions for the test set
all_predictions = []

for text in test_texts:
    # Predict allergens for each test text
    predicted_allergy = predict_allergy(text, model, tokenizer, mlb, device)
    all_predictions.append(predicted_allergy)

# Convert predictions to binary format
all_predictions_binary = mlb.transform(all_predictions)

# Calculate metrics
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

precision = precision_score(test_labels_binary, all_predictions_binary, average='micro')
recall = recall_score(test_labels_binary, all_predictions_binary, average='micro')
f1 = f1_score(test_labels_binary, all_predictions_binary, average='micro')
accuracy = accuracy_score(test_labels_binary, all_predictions_binary)

# Print metrics
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")
print(f"Accuracy: {accuracy:.4f}")

# Inspect classes learned by MultiLabelBinarizer
print("Classes in MultiLabelBinarizer:", mlb.classes_)

# Inspect unique labels in predictions
unique_predicted_labels = set([tuple(label) for label in all_predictions])
print("Unique Predicted Labels:", unique_predicted_labels)

# Combine old and new classes
updated_classes = set(mlb.classes_).union(set(unique_predicted_labels))

# Refit MultiLabelBinarizer with updated classes
mlb = MultiLabelBinarizer(classes=list(updated_classes))
mlb.fit(updated_classes)

for idx, pred in enumerate(all_predictions):
    print(f"Prediction {idx}: {pred}")
    print(f"Type: {type(pred)}")
    print(f"Shape: {np.shape(pred)}\n")

filtered_predictions = []
for prediction in all_predictions:
    flattened_labels = [label for sublist in prediction for label in sublist]
    filtered_labels = [label for label in flattened_labels if label in mlb.classes_]
    filtered_predictions.append(filtered_labels)

filtered_predictions_binary = mlb.transform(filtered_predictions)

# Convert test_labels to a binary matrix (if not already in that format)
if isinstance(test_labels[0], list):
    test_labels_binary = mlb.transform(test_labels)
else:
    test_labels_binary = np.array(test_labels)

print(f"Shape of test_labels_binary: {test_labels_binary.shape}")
print(f"Shape of filtered_predictions_binary: {filtered_predictions_binary.shape}")

print("Example values from test_labels_binary:")
print(test_labels_binary[:5])

# Convert integer labels into multilabel-indicator format
test_labels_binary_multilabel = mlb.transform([[mlb.classes_[label]] for label in test_labels_binary])

assert test_labels_binary_multilabel.shape == filtered_predictions_binary.shape, "Shape mismatch after conversion!"

print("Classes in MultiLabelBinarizer (mlb):", mlb.classes_)

# Flatten and convert classes to strings
flattened_classes = []
for class_ in mlb.classes_:
    if isinstance(class_, tuple):
        flattened_classes.append(", ".join([str(subclass) for subclass in class_]))
    else:
        flattened_classes.append(class_)

from sklearn.metrics import classification_report

print("Classification Report:")
print(classification_report(test_labels_binary_multilabel, filtered_predictions_binary, target_names=flattened_classes, zero_division=1))