{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T13:41:49.241377Z",
     "start_time": "2025-01-30T13:41:49.237789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import re\n",
    "import easyocr\n",
    "import spacy\n",
    "from ultralytics import YOLO\n",
    "from happytransformer import HappyTextToText, TTSettings"
   ],
   "id": "d02b69a1fdfa6c70",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T13:41:53.192286Z",
     "start_time": "2025-01-30T13:41:51.481259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import easyocr\n",
    "reader = easyocr.Reader(['en'], gpu=True, verbose=True)"
   ],
   "id": "e067203be938bda0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T13:53:03.958945Z",
     "start_time": "2025-01-30T13:53:03.953091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'"
   ],
   "id": "d15ba6da384eed4c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T13:53:29.464985Z",
     "start_time": "2025-01-30T13:53:18.613145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load NLP models\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "happy_tt = HappyTextToText(\"T5\", \"prithivida/grammar_error_correcter_v1\")\n",
    "\n",
    "# Unwanted words/phrases to remove\n",
    "EXCLUDED_WORDS = {\"ingredients\", \"may contain\", \"flavour\", \"natural\", \"artificial\", \"colour\"}"
   ],
   "id": "f7959e1386731593",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/30/2025 19:23:29 - INFO - happytransformer.happy_transformer -   Using device: cuda:0\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T13:53:47.037630Z",
     "start_time": "2025-01-30T13:53:47.033011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def correct_text(text):\n",
    "    \"\"\"\n",
    "    Uses a grammar correction model (T5) to fix OCR errors and improve readability.\n",
    "    \"\"\"\n",
    "    args = TTSettings(num_beams=5, min_length=1)\n",
    "    corrected = happy_tt.generate_text(text, args)\n",
    "    return corrected.text.strip()"
   ],
   "id": "843ee9db5924e12d",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T13:53:48.858131Z",
     "start_time": "2025-01-30T13:53:48.853072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_and_split_text(text):\n",
    "    \"\"\"\n",
    "    Uses NLP to tokenize text properly and extract only meaningful words.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    words = [token.text.lower() for token in doc if token.is_alpha]  # Keeps only valid words\n",
    "    return words"
   ],
   "id": "415819dbd55f30f0",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T13:53:50.534196Z",
     "start_time": "2025-01-30T13:53:50.528062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_ingredients_from_image(image, detections):\n",
    "    \"\"\"\n",
    "    Extracts clean ingredient lists from detected areas using OCR.\n",
    "    \"\"\"\n",
    "    extracted_texts = []\n",
    "\n",
    "    for detection in detections:\n",
    "        x1, y1, x2, y2 = map(int, detection['bbox'])\n",
    "\n",
    "        # Ensure bounding box is within image bounds\n",
    "        h, w, _ = image.shape\n",
    "        x1, y1 = max(0, x1), max(0, y1)\n",
    "        x2, y2 = min(w, x2), min(h, y2)\n",
    "\n",
    "        cropped_region = image[y1:y2, x1:x2]\n",
    "\n",
    "        # Skip invalid regions\n",
    "        if cropped_region.size == 0:\n",
    "            continue\n",
    "\n",
    "        results = reader.readtext(cropped_region)\n",
    "\n",
    "        for result in results:\n",
    "            text = result[1]  # Extract recognized text\n",
    "            confidence = result[2]\n",
    "\n",
    "            # Filter out low-confidence detections\n",
    "            if confidence < 0.5:\n",
    "                continue\n",
    "\n",
    "            # Remove standalone numbers (e.g., INS 621)\n",
    "            text = re.sub(r'\\b\\d+\\b', '', text)\n",
    "\n",
    "            # Correct OCR mistakes using NLP\n",
    "            corrected_text = correct_text(text)\n",
    "\n",
    "            # Clean and split text into structured ingredients\n",
    "            words = clean_and_split_text(corrected_text)\n",
    "\n",
    "            # Remove unwanted words (e.g., \"ingredients\", \"flavour\")\n",
    "            words = [word for word in words if word not in EXCLUDED_WORDS]\n",
    "\n",
    "            extracted_texts.extend(words)\n",
    "\n",
    "    return list(set(extracted_texts))  # Remove duplicates"
   ],
   "id": "1f5060398188513a",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T13:55:51.240747Z",
     "start_time": "2025-01-30T13:55:51.233333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_images_with_yolo(model, image_dir, output_size=(800, 600)):\n",
    "    \"\"\"\n",
    "    Process all images in a directory, detect ingredient lists, and extract text.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for file_name in os.listdir(image_dir):\n",
    "        file_path = os.path.join(image_dir, file_name)\n",
    "        image = cv2.imread(file_path)\n",
    "\n",
    "        if image is None:\n",
    "            continue\n",
    "\n",
    "        predictions = model(file_path)\n",
    "        detections = []\n",
    "\n",
    "        for pred in predictions[0].boxes:\n",
    "            bbox = pred.xyxy[0].tolist()\n",
    "            confidence = float(pred.conf[0])\n",
    "            cls = int(pred.cls[0])\n",
    "            label = model.names[cls]\n",
    "\n",
    "            if label == 'ingredients' and confidence > 0.5:\n",
    "                detections.append({'bbox': bbox, 'confidence': confidence, 'class': label})\n",
    "\n",
    "        if detections:\n",
    "            extracted_texts = extract_ingredients_from_image(image, detections)\n",
    "            results[file_name] = extracted_texts\n",
    "\n",
    "            # Draw bounding boxes\n",
    "            for detection in detections:\n",
    "                x1, y1, x2, y2 = map(int, detection['bbox'])\n",
    "                cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(image, detection['class'], (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "            # Resize image\n",
    "            resized_image = cv2.resize(image, output_size)\n",
    "            output_path = os.path.join(image_dir, f\"processed_{file_name}\")\n",
    "            cv2.imwrite(output_path, resized_image)\n",
    "\n",
    "    return results"
   ],
   "id": "102c7d0aad3e7532",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T13:59:20.529038Z",
     "start_time": "2025-01-30T13:58:59.030965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load the trained YOLO model\n",
    "    model = YOLO(r\"F:\\University\\2_Year_02\\2_Year_02_Sem1\\0_Data_Science\\Component_1_Nelishka\\Yolo_11_x\\runs\\detect\\train\\weights\\best.pt\")\n",
    "\n",
    "    # Directory containing images to be checked\n",
    "    image_dir = r\"C:\\Users\\nelis\\Desktop\\labels\"\n",
    "\n",
    "    # Process images and extract ingredient lists\n",
    "    extracted_ingredients = process_images_with_yolo(model, image_dir)\n",
    "\n",
    "    # Print structured ingredients\n",
    "    for image_name, ingredients in extracted_ingredients.items():\n",
    "        print(f\"Image: {image_name}\")\n",
    "        print(ingredients)  # Outputs like ['flour', 'eggs', 'milk', 'butter']"
   ],
   "id": "f81a67ea66f8b022",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\nelis\\Desktop\\labels\\in1057.jpg: 608x640 1 ingredients, 100.3ms\n",
      "Speed: 9.8ms preprocess, 100.3ms inference, 5.4ms postprocess per image at shape (1, 3, 608, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: in1057.jpg\n",
      "['confectionisser', 'freshisser', 'carbox', 'crumbissers', 'sugar', 'gu', 'acid', 'vegetable', 'milkisser', 'milk', 'isser', 'coffee', 'diglycerides', 'dig', 'cellulose', 'fat', 'solid', 'selective', 'diglyceridesisser', 'sodiumisserrate', 'willingness', 'confection', 'carageisseran', 'per', 'crumbs', 'f', 'guar', 'vegetableisser', 'concentrate', 'fresh', 'solidisser', 'crumb', 'meth']\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "73ae1e2b79ceb137"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
